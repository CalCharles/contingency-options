python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 10 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesfop1f10_1/ --optim base --period 1 --reward-form dense > outfop1f10_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 10 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaupp5f10_1/ --optim base --period .05 --reward-form dense > outgaupp5f10_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 10 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaup1f10_1/ --optim base --period .1 --reward-form dense > outgaup1f10_1.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 20 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesfop1f20_1/ --optim base --period 1 --reward-form dense > outfop1f20_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 20 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaupp5f20_1/ --optim base --period .05 --reward-form dense > outgaupp5f20_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 20 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaup1f20_1/ --optim base --period .1 --reward-form dense > outgaup1f20_1.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesfop1f40_1/ --optim base --period 1 --reward-form dense > outfop1f40_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaupp5f40_1/ --optim base --period .05 --reward-form dense > outgaupp5f40_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaup1f40_1/ --optim base --period .1 --reward-form dense > outgaup1f40_1.txt

python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1px_1/ --optim base --period 1 --reward-form dense > outfop1fpx_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5px_1/ --optim base --period .05 --reward-form dense > outgaupp5fpx_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1px_1/ --optim base --period .1 --reward-form dense > outgaup1fpx_1.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1pxb_1/ --optim base --period 1 --reward-form dense > outfop1fpxb_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5pxb_1/ --optim base --period .05 --reward-form dense > outgaupp5fpxb_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1pxb_1/ --optim base --period .1 --reward-form dense > outgaup1fpxb_1.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1pb_1/ --optim base --period 1 --reward-form dense > outfop1fxb_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5pb_1/ --optim base --period .05 --reward-form dense > outgaupp5fxb_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1pb_1/ --optim base --period .1 --reward-form dense > outgaup1fxb_1.txt

python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 256 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1nl1f256_1/ --optim base --period 1 --reward-form dense > outfop1fnl1_1f256.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 256 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5nl1f256_1/ --optim base --period .05 --reward-form dense > outgaupp5fnl1f256_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 256 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1nl1f256_1/ --optim base --period .1 --reward-form dense > outgaup1fnl1f256_1.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1nl1f40_1/ --optim base --period 1 --reward-form dense > outfop1fnl1f40_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5nl1f40_1/ --optim base --period .05 --reward-form dense > outgaupp5fnl1f40_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1nl1f40_1/ --optim base --period .1 --reward-form dense > outgaup1fnl1f40_1.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 128 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1nl1f128_1/ --optim base --period 1 --reward-form dense > outfop1fnl1f128_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 128 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5nl1f128_1/ --optim base --period .05 --reward-form dense > outgaupp5fnl1f128_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 128 --num-layers 1 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1nl1f128_1/ --optim base --period .1 --reward-form dense > outgaup1fnl1f128_1.txt

python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 8 --num-layers 3 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1nl3f8_1/ --optim base --period 1 --reward-form dense > outfop1fnl3f8_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 8 --num-layers 3 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5nl3f8_1/ --optim base --period .05 --reward-form dense > outgaupp5fnl3f8_1.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 8 --num-layers 3 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1nl3f8_1/ --optim base --period .1 --reward-form dense > outgaup1fnl3f8_1.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 10 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesfop1f10_2/ --optim base --period 1 --reward-form dense > outfop1f10_2.txt

python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 10 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaupp5f10_2/ --optim base --period .05 --reward-form dense > outgaupp5f10_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 10 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaup1f10_2/ --optim base --period .1 --reward-form dense > outgaup1f10_2.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 20 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesfop1f20_2/ --optim base --period 1 --reward-form dense > outfop1f20_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 20 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaupp5f20_2/ --optim base --period .05 --reward-form dense > outgaupp5f20_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 20 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaup1f20_2/ --optim base --period .1 --reward-form dense > outgaup1f20_2.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesfop1f40_2/ --optim base --period 1 --reward-form dense > outfop1f40_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaupp5f40_2/ --optim base --period .05 --reward-form dense > outgaupp5f40_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox --state-names Paddle --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/xstatesgaup1f40_2/ --optim base --period .1 --reward-form dense > outgaup1f40_2.txt

python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1pb_2/ --optim base --period 1 --reward-form dense > outfop1xb_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5pb_2/ --optim base --period .05 --reward-form dense > outgaupp5xb_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms xprox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1pb_2/ --optim base --period .1 --reward-form dense > outgaup1xb_2.txt
python paddle_bounce.py --model-form fourier --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms bounds bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/fop1pb_2/ --optim base --period 1 --reward-form dense > outfop1bb_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms bounds bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaupp5pb_2/ --optim base --period .05 --reward-form dense > outgaupp5bb_2.txt
python paddle_bounce.py --model-form gaussian --optimizer-form SARSA --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 100000 --state-forms bounds bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir datasets/caleb_data/cotest/paddlegraphpg --factor 40 --num-layers 2 --greedy-epsilon .2 --lr .0007 --normalize --behavior-policy egq --save-dir datasets/caleb_data/cotest/gaup1pb_2/ --optim base --period .1 --reward-form dense > outgaup1bb_2.txt
