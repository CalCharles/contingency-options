# lr, gradient epochs, width and layers, state, init
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_proxbounds_2_xnorm > PPO/out_PPOe5_10_5_16_2_proxbounds_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms bounds bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_bbounds_2_xnorm > PPO/out_PPOe5_10_5_16_2_bbounds_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnorm > PPO/out_PPOe5_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 1 --train --num-iters 10000 --state-forms prox bounds vel --state-names Paddle Ball Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_bounds_vel_1_xnorm > PPO/out_PPOe5_10_5_16_2_prox_bounds_vel_1_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 1 --train --num-iters 10000 --state-forms prox vel --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_vel_1_xnorm > PPO/out_PPOe5_10_5_16_2_prox_vel_1_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_proxbounds_2_xnorm > PPO/out_PPOe5_10_5_16_2_proxbounds_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms bounds bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_bbounds_2_xnorm > PPO/out_PPOe5_10_5_16_2_bbounds_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnorm > PPO/out_PPOe5_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 1 --train --num-iters 10000 --state-forms prox bounds vel --state-names Paddle Ball Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_bounds_vel_1_xnorm > PPO/out_PPOe5_10_5_16_2_prox_bounds_vel_1_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 1 --train --num-iters 10000 --state-forms prox vel --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_vel_1_xnorm > PPO/out_PPOe5_10_5_16_2_prox_vel_1_xnorm_2.txt

python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 1 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_1_5_16_2_prox_2_xnorm > PPO/out_PPOe5_1_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 2 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_2_5_16_2_prox_2_xnorm > PPO/out_PPOe5_2_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 5 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_5_5_16_2_prox_2_xnorm > PPO/out_PPOe5_5_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 20 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_20_5_16_2_prox_2_xnorm > PPO/out_PPOe5_20_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 1 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_1_5_16_2_prox_2_xnorm > PPO/out_PPOe5_1_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 2 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_2_5_16_2_prox_2_xnorm > PPO/out_PPOe5_2_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 5 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_5_5_16_2_prox_2_xnorm > PPO/out_PPOe5_5_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 20 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_20_5_16_2_prox_2_xnorm > PPO/out_PPOe5_20_5_16_2_prox_2_xnorm_2.txt

python paddle_bounce.py --model-form basic --7imizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-3 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe3_10_5_16_2_prox_2_xnorm > PPO/out_PPOe3_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-2 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe2_10_5_16_2_prox_2_xnorm > PPO/out_PPOe2_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-4 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe4_10_5_16_2_prox_2_xnorm > PPO/out_PPOe4_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-6 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe6_10_5_16_2_prox_2_xnorm > PPO/out_PPOe6_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-6 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe6_10_5_16_2_prox_2_xnorm > PPO/out_PPOe6_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-7 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe7_10_5_16_2_prox_2_xnorm > PPO/out_PPOe7_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-8 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe8_10_5_16_2_prox_2_xnorm > PPO/out_PPOe8_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim Adam --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5Adam_10_5_16_2_prox_2_xnorm > PPO/out_PPOe5Adam_10_5_16_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-3 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe3_10_5_16_2_prox_2_xnorm > PPO/out_PPOe3_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-2 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe2_10_5_16_2_prox_2_xnorm > PPO/out_PPOe2_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-4 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe4_10_5_16_2_prox_2_xnorm > PPO/out_PPOe4_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-6 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe6_10_5_16_2_prox_2_xnorm > PPO/out_PPOe6_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-6 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe6_10_5_16_2_prox_2_xnorm > PPO/out_PPOe6_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-7 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe7_10_5_16_2_prox_2_xnorm > PPO/out_PPOe7_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-8 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe8_10_5_16_2_prox_2_xnorm > PPO/out_PPOe8_10_5_16_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim Adam --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5Adam_10_5_16_2_prox_2_xnorm > PPO/out_PPOe5Adam_10_5_16_2_prox_2_xnorm_2.txt

python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --dist-interval 3 --dist-beta .01 --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnormde01 > PPO/out_PPOe5_10_5_16_2_prox_2_xnormde01.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --dist-interval 3 --dist-beta .03 --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnormde03 > PPO/out_PPOe5_10_5_16_2_prox_2_xnormde03.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --dist-interval 3 --dist-beta .01 --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnormde01 > PPO/out_PPOe5_10_5_16_2_prox_2_xnormde01_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --dist-interval 3 --dist-beta .03 --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnormde03 > PPO/out_PPOe5_10_5_16_2_prox_2_xnormde03_2.txt

python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 32 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_32_2_prox_2_xnorm > PPO/out_PPOe5_10_5_32_2_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 8 --num-layers 3 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_8_3_prox_2_xnorm > PPO/out_PPOe5_10_5_8_2_prox_3_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 2 --num-layers 1 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_2_1_prox_2_xnorm > PPO/out_PPOe5_10_5_2_1_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 32 --num-layers 1 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_32_1_prox_2_xnorm > PPO/out_PPOe5_10_5_32_1_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 2 --num-layers 0 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_1_0_prox_2_xnorm > PPO/out_PPOe5_10_5_1_0_prox_2_xnorm.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 32 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_32_2_prox_2_xnorm > PPO/out_PPOe5_10_5_32_2_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 8 --num-layers 3 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_8_3_prox_2_xnorm > PPO/out_PPOe5_10_5_8_2_prox_3_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 2 --num-layers 1 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_2_1_prox_2_xnorm > PPO/out_PPOe5_10_5_2_1_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 32 --num-layers 1 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_32_1_prox_2_xnorm > PPO/out_PPOe5_10_5_32_1_prox_2_xnorm_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 2 --num-layers 0 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_1_0_prox_2_xnorm > PPO/out_PPOe5_10_5_1_0_prox_2_xnorm_2.txt


python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xuni --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xuni > PPO/out_PPOe5_10_5_16_2_prox_2_xuni.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xuni --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xuni > PPO/out_PPOe5_10_5_16_2_prox_2_xuni.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xuni --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xuni > PPO/out_PPOe5_10_5_16_2_prox_2_xuni_2.txt
python paddle_bounce.py --model-form basic --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox --state-names Paddle --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 16 --num-layers 2 --greedy-epsilon 1 --lr 1e-5 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xuni --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xuni > PPO/out_PPOe5_10_5_16_2_prox_2_xuni_2.txt


python paddle_bounce.py --model-form gaumulti --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 20 --num-layers 2 --greedy-epsilon 1 --lr 1e-6 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --num-population 64 --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnorm_gaumulti > PPO/out_PPOe5_10_5_16_2_prox_2_xnorm_gaumulti.txt
python paddle_bounce.py --model-form gaumulti --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 20 --num-layers 2 --greedy-epsilon 1 --lr 1e-6 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --num-population 64 --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnorm_gaumulti_1 > PPO/out_PPOe5_10_5_16_2_prox_2_xnorm_gaumulti_1.txt
python paddle_bounce.py --model-form gaumulti --optimizer-form PPO --record-rollouts "data/action/" --train-edge "Paddle->Ball" --num-stack 2 --train --num-iters 10000 --state-forms prox bounds --state-names Paddle Ball --base-node Paddle --changepoint-dir ../datasets/caleb_data/cotest/paddlegraph --factor 20 --num-layers 2 --greedy-epsilon 1 --lr 1e-6 --normalize --behavior-policy egq --optim RMSprop --period .05 --reward-form neg --gamma .99 --buffer-steps 10000 --num-grad-states 5 --grad-epoch 10 --greedy-epsilon-decay 800 --init-form xnorm --num-population 64 --save-dir ../datasets/caleb_data/cotest/PPOe5_10_5_16_2_prox_2_xnorm_gaumulti_2 > PPO/out_PPOe5_10_5_16_2_prox_2_xnorm_gaumulti_2.txt
